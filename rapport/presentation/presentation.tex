\documentclass{beamer}
\useinnertheme{rectangles}
\usecolortheme{orchid}
\newenvironment{proenv}{\only{\setbeamercolor{local structure}{fg=green}}}{}
\newenvironment{conenv}{\only{\setbeamercolor{local structure}{fg=red}}}{}
\addtobeamertemplate{footline}{\textcolor{blue}{\small\insertframenumber/\inserttotalframenumber}}

\usepackage[utf8]{inputenc} % accents 8 bits dans le fichier
\usepackage[T1]{fontenc}      % accents codés dans la fonte
\usepackage[french]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage{hepnames}
\usepackage{tikz-feynman}
\usepackage[version=4]{mhchem} 
\usepackage[mode=buildnew]{standalone}
\usepackage{booktabs}
\usepackage{wasysym}
\usepackage{pgfplots}

\pgfplotsset{compat=1.3}
\DeclareSIUnit\year{yr}

% Here's where the presentation starts, with the info for the title slide

\beamertemplatenavigationsymbolsempty
\makeatletter
\newcommand\titlegraphicii[1]{\def\inserttitlegraphicii{#1}}
\titlegraphicii{}
\setbeamertemplate{title page}
{
  \vbox{}
   {\usebeamercolor[fg]{titlegraphic}\inserttitlegraphic\hfill\inserttitlegraphicii\par}
  \begin{centering}
    \begin{beamercolorbox}[sep=8pt,center]{institute}
      \usebeamerfont{institute}\insertinstitute
    \end{beamercolorbox}
    \begin{beamercolorbox}[sep=8pt,center]{title}
      \usebeamerfont{title}\inserttitle\par%
      \ifx\insertsubtitle\@empty%
      \else%
        \vskip0.25em%
        {\usebeamerfont{subtitle}\usebeamercolor[fg]{subtitle}\insertsubtitle\par}%
      \fi%     
    \end{beamercolorbox}%
    \vskip1em\par
    \begin{beamercolorbox}[sep=8pt,center]{date}
      \usebeamerfont{date}\insertdate
    \end{beamercolorbox}%\vskip0.5em
    \begin{beamercolorbox}[sep=8pt,center]{author}
      \usebeamerfont{author}\insertauthor
    \end{beamercolorbox}
  \end{centering}
  %\vfill
}
\makeatother

\title[Détection de virus informatique]{Classifications de programmes malicieux et non-malicieux\\ à partir de propriétés binaires}
\author{Matthias \bsc{Beaupère}, Pierre \bsc{Granger}}
\date{\today}

\subtitle{Projet DA -- M2 CHPS}
\date{\today}
% \titlegraphic{\includegraphics[height=1.7cm, keepaspectratio]{img/ens.jpg}}
% \titlegraphicii{\includegraphics[height=1.7cm, keepaspectratio]{img/uppsala.pdf}}


\begin{document}
\setbeamercolor{captioncolor}{fg=white,bg=red!80!white}
\setbeamertemplate{caption}{%
\begin{beamercolorbox}[wd=0.8\linewidth, sep=.2ex]{captioncolor}\tiny\centering\insertcaption%
\end{beamercolorbox}%
}

\begin{frame}
  \titlepage
\end{frame}

% These three lines create an automatically generated table of contents.


\begin{frame}{Présentation du dataset - Histogrammes}
\begin{center}
		\begin{figure}
			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=5cm,
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}, fill=black!50!white, draw=black]
			table[y index=0] {../data/hist_features.dat};
			\legend{Ensemble des programmes}
			\end{axis}
			\end{tikzpicture}

			\caption{Histogramme du nombre de caractéristiques possédées par chaque programme\label{hist_features}}
		\end{figure}
	\end{center}
\end{frame}

\begin{frame}{Présentation du dataset - Histogrammes}
	\begin{center}
	\begin{figure}
	\begin{tikzpicture}
	\begin{axis}[
	width=\linewidth,
	height=6cm,
	xmin=0,xmax=400,
	ymin=0, ymax=300,
	ybar interval,
	xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
	x tick label style= {rotate=90,anchor=east},
	ylabel={Nombre de caractéristiques},
	xlabel={Nombre de programmes}
	],
	\addplot+[hist={bins=20, data max=400,data min=0}]
	table[y index=0] {../data/hist_individuals.dat};
	% \addplot[sharp plot,mark=square*,black]
	% coordinates
	% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
	\end{axis}
	\end{tikzpicture}
	\caption{Histogramme du nombre de programmes possédant chaque caractéristique\label{hist_individuals}}
	\end{figure}
	\end{center}
\end{frame}

\begin{frame}{Régression logistique - data-splitting}
	\begin{center}
			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.45\linewidth,
						height=6cm,
						ylabel={Score moyen},
						clip mode=individual,
						],
						\addplot table [x=train_size, y=mean, only marks] {../data/logreg_l1_c05_trainsize.dat};
						\addplot[samples=100, no markers, domain=0.1:0.99, style=thick, color=red]{x^0.09162945*exp(-0.12192647)};
						\addplot[mark=none, style=thick, color=green] coordinates {(0.8,0.7) (0.8,0.9)};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.45\linewidth,
						height=6cm,
						ylabel={Ecart type du score},
						],
						\addplot table [x=train_size, y=std, only marks] {../data/logreg_l1_c05_trainsize.dat};
						\addplot[mark=none, style=thick, color=green] coordinates {(0.8,0) (0.8,0.15)};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				Proportion utilisée pour l'apprentissage
				\caption{Evolutions de la valeur moyenne et de l'écart type du score en fonction de la proportion de données utilisées pour l'apprentissage dans le cas de la régression logistique. L'évaluation est effectuée sur la partie complémentaire.\label{logreg_meanstd}}
			\end{figure}
		\end{center}
\end{frame}

\begin{frame}{Regression logistique - choix de la pénalisation}
	\begin{figure}
			\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
					width=\linewidth,
					height=6cm,
					ylabel={Moyenne du score},
					xlabel={$C$ (L1)},
					legend style={at={(0.95,0.7)}},
					],
					\addplot table [x=C, y=correct, only marks] {../data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=false, only marks] {../data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=missed, only marks] {../data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\legend{Résultat correct, Faux négatif, Faux positif}
				\end{axis}
			\end{tikzpicture}
			\caption{\'Evolution du score en fonction de l'importance de la pénalisation\label{fig:l1_C}}
			\end{center}
		\end{figure}
\end{frame}

\begin{frame}{Arbre de décision - data-splitting}
	\begin{figure}
		\begin{tikzpicture}
			\begin{axis}[
				width=0.4\linewidth,
				height=6cm,
				ylabel={Moyenne de précision},
				xlabel={Taille de l'ensemble de test}
				],
				\addplot table [x index=0, y index=1, only marks] {../data/decision_tree.txt};
			\end{axis}
		\end{tikzpicture}
		\begin{tikzpicture}
			\begin{axis}[
				width=0.4\linewidth,
				height=6cm,
				ylabel={Ecart-type en précision},
				xlabel={Taille de l'ensemble de test}
				],
				\addplot table [x index=0, y index=2, only marks] {../data/decision_tree.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Moyenne et Ecart-type pour 1000 data-splitting}
		\label{data-splitting-dt}
	\end{figure}
\end{frame}

\begin{frame}{Arbre de décision - Validation croisée}
	\begin{figure}
	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[
				width=0.5\linewidth,
				height=6cm,
				ylabel={Moyenne de précision},
				xlabel={Nombre de parts},
				ymin=0
				],
				\addplot table [x index=0, y index=1, only marks] {../data/decision_tree_cv.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Moyenne pour 100 cross-validations}
		\label{cv_dt}
	\end{center}
	\end{figure}
\end{frame}

\begin{frame}{Random Forest - Validation croisée}

	\begin{figure}
	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[
				width=0.7\linewidth,
				height=6cm,
				ylabel={Moyenne de précision},
				xlabel={Nombre de parts},
				ymin=0
				],
				\addplot table [x index=0, y index=1, only marks] {../data/random_forest.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Impact du nombre de division (100 répétitions)}
		\label{random_forest}
	\end{center}
	\end{figure}
\end{frame}

\begin{frame}{Random Forest - Impact du nombre d'arbres}
	\begin{figure}
	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[
				width=0.7\linewidth,
				height=6cm,
				ylabel={Moyenne de précision},
				xlabel={Nombre d'estimateurs}
				],
				\addplot table [x index=0, y index=1, only marks] {../data/random_forest_estimators.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Impact du nombre d'estimateurs (100 répétitions)}
		\label{rf_estimators}
	\end{center}
	\end{figure}
\end{frame}


\begin{frame}{Random Forest - Impact de la profondeur}
	\begin{figure}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
					width=0.7\linewidth,
					height=6cm,
					ylabel={Moyenne de précision},
					xlabel={Profondeur maximum d'arbre}
					],
					\addplot table [x index=0, y index=1, only marks] {../data/random_forest_depth.txt};
				\end{axis}
			\end{tikzpicture}
			\caption{Impact de la profondeur maximale (100 répétitions)}
			\label{rf_depth}
		\end{center}
	\end{figure}
\end{frame}

\begin{frame}{Gradient Boosting - Impact de la profondeur}
	\begin{figure}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
					width=0.7\linewidth,
					height=6cm,
					ylabel={Moyenne de précision},
					xlabel={Profondeur maximale des arbres}
					],
					\addplot table [x index=0, y index=1, only marks] {../data/gradiant_boosting_estimators.txt};
				\end{axis}
			\end{tikzpicture}
			\caption{Gradient Boosting - Impact de la profondeur maximale (30 répétitions)}
			\label{gb_estimators}
		\end{center}
	\end{figure}
\end{frame}

\begin{frame}{Analyse des résultats}
\begin{table}
	\small
	\begin{center}
	\begin{tabular}{cccc}
		\toprule
		Méthode  &	Score  &	Faux positifs  &	Faux négatifs \\
		\midrule
		Régression logistique 	& \SI{87}{\percent} 	 &	\SI{11}{\percent}  	& \SI{2}{\percent} \\
		Arbre de décision & \SI{79}{\percent} & \SI{17}{\percent} & \SI{4}{\percent} \\
		Random forest & \SI{81}{\percent} & \SI{16}{\percent} & \SI{3}{\percent} \\
		Random forest \\ avec élimination de caractéristiques& \SI{83}{\percent} & \SI{14}{\percent} & \SI{3}{\percent} \\
		Gradient boosting & \SI{85}{\percent} & \SI{12}{\percent} & \SI{3}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption{Résumé des résultats obtenus \label{table:results}}
	\end{center}
\end{table}

\end{frame}

\begin{frame}{Conclusion}
	\begin{block}{Pour aller plus loin}
		\begin{itemize}
			\item \'Etudier plus précisément le gradient-boosting
			\item Optimiser l'élimination de caractéristiques
			\item Combiner différents estimateurs
		\end{itemize}
	\end{block}

	\begin{alertblock}{Conclusion}
		\begin{itemize}
			\item Régresion logistique la plus efficace
			\item Arbre de décision très chronophage
			\item Jeu de données peut-être biaisé ?
		\end{itemize}
	\end{alertblock}
\end{frame}


\end{document}
