\documentclass[11pt,a4paper]{article}


\setlength{\topmargin}{-55pt}%
\setlength{\oddsidemargin}{-20pt}%
\setlength{\textwidth}{490pt}%
\setlength{\textheight}{700pt}%
\setlength{\headsep}{20pt}%
\setlength{\headheight}{14pt}

\usepackage[utf8]{inputenc} % accents 8 bits dans le fichier
\usepackage[T1]{fontenc}      % accents codés dans la fonte
\usepackage[french]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage{hepnames}
\usepackage[version=4]{mhchem} 
\usepackage[mode=buildnew]{standalone}
\usepackage{booktabs}
\usepackage{color, colortbl}
\usepackage{appendix}
\usepackage{pgfplots}
\usepackage[hidelinks]{hyperref}

\pgfplotsset{compat=1.3}

\addto\captionsfrench{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Table des matières}
}

\DecimalMathComma

\lhead{Détection de virus informatique}      %en-tête
\chead{}%
\rhead{}%
\lfoot{}%\tiny{Pierre GRANGER}}%
\cfoot{}%
\rfoot{\thepage}%
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}
\pagestyle{fancy}

\DeclareSIUnit\year{yr}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newcommand{\graphtikz}[2]{
\begin{figure}[h]
	\begin{center}
		\shorthandoff{:!}
		\includestandalone[#1]{#2}
		\shorthandon{:!}
	\end{center}
\end{figure}
}

\definecolor{green}{rgb}{0.2,0.8,0.2}

\begin{document}
\begin{center}

	{\LARGE\centering Classifications de programmes malicieux et non-malicieux\\ à partir de propriétés binaires}\\[1cm]

	{ Matthias \bsc{Beaupère}, Pierre \bsc{Granger}}\\[0.5cm]
	{Rapport DA - CHPS - \today}
\end{center}

\tableofcontents

\section{Présentation du jeu de données}
	Nos données proviennent de la base de données UCI\cite{UCI}.
	Cette base de données a été obtenue à partir de l'étude de 373 programmes informatiques malicieux et non-malicieux selon le processus expliqué dans un article de recherche en 2007 \cite{article}. Cet article développe une méthode permettant d'extraire des caractéristiques à partir d'exécutables malins et bénins afin d'effectuer par la suite une classification de ces exécutables permettant de les distinguer. Trois types de caractéristiques sont extraites : des n-uplets binaires, des n-uplets assembleur et des appels à des fonctions appartenant à des librairies extérieures. Les caractéristiques binaires sont extraites des exécutables binaires tandis que les caractéristique assembleur sont obtenues après désassemblage de l'exécutable. Les caractéristiques liées aux appels de fonctions sont extraites depuis l'entête du programme.

\section{Objectifs}
	Nous nous proposons dans ce projet d'utiliser le jeu de données précédemment décrit afin d'obtenir la meilleure classification possible entre les virus informatiques et les programmes bénins. Nous avons choisi d'utiliser le language Python et plus particulièrement son module Scikit-learn \cite{sklearn} durant ce projet.

\section{Pré-traitement des données}
	Nous avons commencé notre étude des données par quelques visualisations de notre jeu de données. Nous avons tout d'abord visualisé l'histogramme du nombre de caractéristiques possédé par les programmes du jeu de données représenté sur la figure \ref{hist_features}. On peut observer sur cet histogramme que la majorité des programmes possèdent une centaine de caractéristiques tandis qu'ils sont très peu à les posséder toutes ou bien à n'en avoir aucune. On peut en outre remarquer que la quasi totalité des virus possèdent un nombre de caractéristique situé entre 80 et 110 tandis qu'il existe des programmes bénins avec plus ou moins de caractéristiques. Cette observation pourra nous mener à tenter de restreindre certaines analyses futures aux programmes possédant entre 80 et 110 caractéristiques en supposant que les programmes bénins ne respectant pas ce critère peuvent être considérés comme des valeurs extrèmes.
	On peut en outre observer sur l'histogramme représenté en figure \ref{hist_individuals} que la majorité des caractéristiques ne sont possédées que par quelques dizaines de programmes. On observe néanmoins qu'il existe un nombre non négligeable de caractéristiques partagées par un grand nombre de programmes. On pourra se proposer par la suite de ne pas considérer les caractéristiques correspondantes car elles sont moins significatives.


	\begin{center}
		\begin{figure}
			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}] table[y index=0] {data/hist_features_ok.dat};
			\legend{Programmes bénins}
			\end{axis}
			\end{tikzpicture}
			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}, fill=red!50!white, draw=red] table[y index=0] {data/hist_features_virus.dat};
			\legend{Programmes malicieux}
			\end{axis}
			\end{tikzpicture}

			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}, fill=black!50!white, draw=black]
			table[y index=0] {data/hist_features.dat};
			\legend{Ensemble des programmes}
			\end{axis}
			\end{tikzpicture}

			\caption{Histogramme du nombre de caractéristiques possédé par chaque programme\label{hist_features}}
		\end{figure}
	\end{center}

	\begin{center}
	\begin{figure}
	\begin{tikzpicture}
	\begin{axis}[
	width=\linewidth,
	height=6cm,
	xmin=0,xmax=400,
	ymin=0, ymax=300,
	ybar interval,
	xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
	x tick label style= {rotate=90,anchor=east},
	ylabel={Nombre de caractéristiques},
	xlabel={Nombre de programmes}
	],
	\addplot+[hist={bins=20, data max=400,data min=0}]
	table[y index=0] {data/hist_individuals.dat};
	% \addplot[sharp plot,mark=square*,black]
	% coordinates
	% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
	\end{axis}
	\end{tikzpicture}
	\caption{Histogramme du nombre de programme possédant chaque caractéristique\label{hist_individuals}}
	\end{figure}
	\end{center}

\section{Techniques de validation}

	On présente ici les deux techniques utilisées pour valider les modèles de classification.

	\subsection{Data-splitting}		
		La première technique de validation utilisée est la technique de data-splitting. On divise aléatoirement le jeu de données en deux. La première partie sert à entrainer le modèle tandis que la seconde est utilisée pour valider le modèle en comparant les prédictions du modèle et les valeurs réelles.
		Cette technique produit des résultats très différents suivant la répartition des données dans les deux jeux. C'est pourquoi on rejouera souvent un grand nombre de fois le data-splitting et on observera la moyenne et l'écart-type pour connaitre la robustesse de la validation.

	\subsection{Cross-validation}

		La deuxième technique consiste à diviser le jeu de données en $n$ parties égales. On itère sur chaque partie de la façon suivante: les $n-1$ autres parties servent à entrainer le modèle et la partie courante est utilisée pour le valider. 

\section{Différents algo}
	\subsection{Régression logistique}
		La régression logistique permet facilement d'effectuer une régression binomiale sur des caractéristiques binaires afin d'obtenir une classification binaire d'où sa mise en oeuvre dans le problème qui nous occupe.

		La régression logistique permet d'effectuer une pénalisation de type L1 ou L2 afin de limiter le nombre de caractéristiques significatives dans le calcul de la régression. Cette pénalisation peut se parametrer avec Scikit-Learn au travers d'un paramètre $C$ qui est l'inverse de la constante de régularisation. Ainsi on augmente la pénalisation lorsque l'on diminue $C$.

		On commence par étudier quelle valeur de $C$ permet d'obtenir les meilleurs résultats. On peut voir représenté sur la figure \ref{fig:l1_C} l'impact de la valeur de $C$ sur le score obtenu dans le cas de la pénalisation L1. On peut observer que la valeur optimale se situe aux alentours de $C=0.4$. En effet, pour une valeur inférieure, la constante de régularisation devient trop importantes et trop de caractéristiques sont éliminées d'où une chute du score. Pour $C>0.4$, on observe une légère pente descendante car l'impact de la pénalisation devient alors très faible. Le taux de faux-négatifs commence alors à très légèrement augmenter. Il semble qu'aucune valeur spécifique permette d'optimiser le nombre de faux-négatifs par rapport aux faux-positifs. Nous avons aussi testé la pénalisation L2 mais elle offrait des résultats légèrement inférieurs. On choisit donc pour la suite la pénalisation L1 et $C=0.4$.

		Dans un second temps, on peut tenter d'optimiser la proportion à utiliser entre les données d'entrainement de test afin d'obtenir les meilleurs résultats. On peut observer sur la figure \ref{logreg_meanstd} les tracés de la valeur moyenne et de l'écart-type du score obtenus après 500 répétitions aléatoires. Le score moyen augmente en suivant une loi de puissance de paramètre $0.09$ lorsque la quantité de données d'entrainement augmente. Néanmoins l'écart-type commence à exploser lorsque la proportion des données d'entrainement dépasse $0.8$ ce qui est attendu car alors la quantité d'exemples de test devient très faible. Le choix le plus judicieux du paramètre de proportion semble alors être $0.8$ ce qui permet d'atteindre une précision moyenne de $\SI{87}{\percent}$.

		Lorsque l'on tente de restreindre le nombre de programmes à étudier en ne sélectionnant que ceux avec un nombre de caractéristiques entre 80 et 110, la précision moyenne chute à $\SI{84}{\percent}$. Il est propable que cette restriction ne soit pas judicieuse car on ne possède déjà qu'une population de très petite taille devant le nombre de caractéristiques. Néanmoins lorsque l'on élimine toutes les caractéristiques faiblement représentatives c'est à dire celles possédées par plus de 240 individus, on obtient des résultats tout aussi bon qu'en les laissant. Ainsi, il peut être judicieux de ne pas tenir compte de ces caractéristiques.



		\begin{figure}
			\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
					width=0.7\linewidth,
					height=6cm,
					ylabel={Moyenne du score},
					xlabel={$C$ (L1)},
					legend style={at={(0.95,0.7)}},
					],
					\addplot table [x=C, y=correct, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=false, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=missed, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\legend{Résultat correct, Faux négatif, Faux positif}
				\end{axis}
			\end{tikzpicture}
			\caption{\'Evolution du score en fonction de l'importance de la pénalisation\label{fig:l1_C}}
			\end{center}
		\end{figure}

		\begin{center}
			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Score moyen},
						xlabel={Proportion utilisée pour l'apprentissage}
						],
						\addplot table [x=train_size, y=mean, only marks] {data/logreg_l1_c05_trainsize.dat};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Ecart type du score},
						xlabel={Proportion utilisée pour l'apprentissage}
						],
						\addplot table [x=train_size, y=std, only marks] {data/logreg_l1_c05_trainsize.dat};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				\caption{Evolutions de la valeur moyenne et de l'écart type du score en fonction de la proportion de données utilisées pour l'apprentissage dans le cas de la régression logistique. L'évaluation est effectuée sur la partie complémentaire.\label{logreg_meanstd}}
			\end{figure}
		\end{center}


	\subsection{SVM}

		% \begin{figure}[h]
		% 	\centering
		% 	\begin{tikzpicture}
		% 		\begin{axis}[
		% 			xlabel={$Q_{\beta\beta}$ (\si{MeV})},
		% 			ylabel style={align=center},
		% 			ylabel={Events not depositing energy \\ in the considered medium (\si{\percent})},
		% 			legend pos=north east,
		% 			legend entries={fibers, buffer}]
		% 			\addplot table [x=Qbb, y=percent, only marks] {increase.txt};
		% 			\addplot table [x=Qbb, y=percent2, only marks] {increase.txt};
		% 		\end{axis}
		% 	\end{tikzpicture}
		% 	\caption{Proportions of events not depositing energy in the fibers as a function of $Q_{\beta\beta}$ of the considered isotope. \label{figure:en_vs_qbb}}
		% \end{figure}

	\subsection{SVC}
	\subsection{Classification avec kmeans}

	\subsection{Arbre de décision}

		\subsubsection{Arbre simple}
			Comme premier classificateur on utilise un unique arbre de décision. On compare les deux méthodes de validation : tout d'abord le data-splitting et ensuite la validation croisée. Dans chaque cas on observe l'impact de la proportion des données d'entrainement sur la précision et la robustesse du modèle.

			La figure \ref{data-splitting-dt} nous donne l'évolution de la précision moyenne et de l'écart-type obtenu pour mille rejeu du data-splitting. Chaque abscisse donne un proportion des données de test. On observe un minimum d'écart-type à l'abscisse $175$. Cela montre que le modèle le plus robuste correspond à des données de test représentant environ 45\% de la population.

			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Taille de l'ensemble de test}
						],
						\addplot table [x index=0, y index=1, only marks] {data/decision_tree.txt};
					\end{axis}
				\end{tikzpicture}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Ecart-type en précision},
						xlabel={Taille de l'ensemble de test}
						],
						\addplot table [x index=0, y index=2, only marks] {data/decision_tree.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Moyenne et Ecart-type pour 1000 data-splitting}
				\label{data-splitting-dt}
			\end{figure}

			La figure \ref{cv_dt} représente précision du modèle avec un validation par cross-validation. Nous avons rejoué 100 fois le scénario pour obtenir une moyenne. Nous n'avons pas représenté l'écart-type ici car il est trop faible pour avoir une signification. L'abscisse de cette figure indique le nombre de divisions de la validation croisée.
			On en déduit qu'entre 4 et 10 divisions la précision change peu. De plus un nombre de 7 division semble être la valeur optimale.

			\begin{figure}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Nombre de parts},
						ymin=0
						],
						\addplot table [x index=0, y index=1, only marks] {data/decision_tree_cv.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Moyenne pour 100 cross-validations}
				\label{cv_dt}
			\end{center}
			\end{figure}


		\subsubsection{Random forest}
		
			Le deuxième classificateur est le Random Forest. Il s'agit d'un ensemble d'arbres construits aléatoirement et pondérés en fonction de leur résultat. Pour ce classificateur on utilisera uniquement la validation par validation croisée.

			Le résultat de la première étude est présenté figure \ref{random_forest}. Il s'agit de regarder l'influence du nombre de découpage sur la précision. On observe une tendance similaire à celle vu dans la figure \ref{cv_dt}, avec néammoins une amplitude atténuée. On en déduit que l'on peut choisir entre 4 et 10 divisions sans grand impact.


			\begin{figure}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.7\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Nombre de parts},
						ymin=0
						],
						\addplot table [x index=0, y index=1, only marks] {data/random_forest.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Impact du nombre de division (100 répétitions)}
				\label{random_forest}
			\end{center}
			\end{figure}

			La seconde étude consiste à observer l'influence du nombre d'arbres sur la précision. Les résultats sont présentés figure \ref{rf_estimators}. On observe que si on choisit un nombre trop faible d'estimateurs, la précision se dégrade très rapidement. En outre on remarque qu'a partir de 50 estimateurs la précision reste constante, il serait donc inutile de choisir un nombre d'estimateurs supérieur à 50 car cela reviendrait à consommer de la puissance de calcul inutilement.

			\begin{figure}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.7\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Nombre d'estimateurs}
						],
						\addplot table [x index=0, y index=1, only marks] {data/random_forest_estimators.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Impact du nombre d'estimateurs (100 répétitions)}
				\label{rf_estimators}
			\end{center}
			\end{figure}


			La troisième et dernière étude du Random Forest présente l'impact de la profondeur des arbres sur la précision de l'algorithme. On peut observer sur la figure \ref{rf_depth} les résultats obtenus. On retrouve la même tendance que dans l'étude précédente à propos du nombre d'arbre : si on diminue la profondeur, la précision se dégrade. Par ailleurs la précision stagne pour une profondeur supérieur à 20.

			\begin{figure}
				\begin{center}
					\begin{tikzpicture}
						\begin{axis}[
							width=0.7\linewidth,
							height=6cm,
							ylabel={Moyenne de précision},
							xlabel={Profondeur maximum d'arbre}
							],
							\addplot table [x index=0, y index=1, only marks] {data/random_forest_depth.txt};
						\end{axis}
					\end{tikzpicture}
					\caption{Impact de la profondeur maximale (100 répétitions)}
					\label{rf_depth}
				\end{center}
			\end{figure}

			On peut finalement tenter d'apliquer l'algorithme de Random Forest en éliminant les caractéristiques faiblement représentatives c'est à dire celle possédées par plus de 240 individus. On s'attend à ce que cette élimination soit particulièrement profitable aux algorithmes d'arbre de décision et cela semble être effictivement le cas. En effet le taux de réussite augmente de 3 points pour s'établir à \SI{83}{\percent} lorsque que l'on effectue cette coupure.

		\subsubsection{Gradient Boosting}

			\begin{figure}
				\begin{center}
					\begin{tikzpicture}
						\begin{axis}[
							width=0.7\linewidth,
							height=6cm,
							ylabel={Moyenne de précision},
							xlabel={Nombre de parts}
							],
							\addplot table [x index=0, y index=1, only marks] {data/gradiant_boosting.txt};
						\end{axis}
					\end{tikzpicture}
					\caption{Impact de la profondeur maximale}
					\label{rf_depth}
				\end{center}
			\end{figure}
\section{Analyse des résultats}

	\begin{table}
	\begin{center}
	\begin{tabular}{cccc}
		\toprule
		Méthode  &	Score  &	Faux positifs  &	Faux négatifs \\
		\midrule
		Régression logistique 	& \SI{87}{\percent} 	 &	\SI{11}{\percent}  	& \SI{2}{\percent} \\
		Arbre de décision & \SI{79}{\percent} & \SI{17}{\percent} & \SI{4}{\percent} \\
		Random forest & \SI{81}{\percent} & \SI{16}{\percent} & \SI{3}{\percent} \\
		Random forest \\ avec élimination de caractéristiques& \SI{83}{\percent} & \SI{14}{\percent} & \SI{3}{\percent} \\
		Gradient boosting & \SI{85}{\percent} & \SI{12}{\percent} & \SI{3}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption{Résumé des résultats obtenus \label{table:results}}
	\end{center}
\end{table}

\section{Pour aller plus loin...}
cumuler n estimateurs

\section{Conclusion}
	gradient boosting + random forest : des temps de calcul très très long

\bibliographystyle{unsrt}
\bibliography{synopsis.bib}

%\input{appendix}

\end{document}
