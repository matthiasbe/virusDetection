\documentclass[11pt,a4paper]{article}


\setlength{\topmargin}{-55pt}%
\setlength{\oddsidemargin}{-20pt}%
\setlength{\textwidth}{490pt}%
\setlength{\textheight}{700pt}%
\setlength{\headsep}{20pt}%
\setlength{\headheight}{14pt}

\usepackage[utf8]{inputenc} % accents 8 bits dans le fichier
\usepackage[T1]{fontenc}      % accents codés dans la fonte
\usepackage[french]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage{hepnames}
\usepackage[version=4]{mhchem} 
\usepackage[mode=buildnew]{standalone}
\usepackage{booktabs}
\usepackage{color, colortbl}
\usepackage{appendix}
\usepackage{pgfplots}
\usepackage[hidelinks]{hyperref}

\pgfplotsset{compat=1.3}

\addto\captionsfrench{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Table des matières}
}

\DecimalMathComma

\lhead{Détection de virus informatique}      %en-tête
\chead{}%
\rhead{}%
\lfoot{}%\tiny{Pierre GRANGER}}%
\cfoot{}%
\rfoot{\thepage}%
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}
\pagestyle{fancy}

\DeclareSIUnit\year{yr}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newcommand{\graphtikz}[2]{
\begin{figure}[h]
	\begin{center}
		\shorthandoff{:!}
		\includestandalone[#1]{#2}
		\shorthandon{:!}
	\end{center}
\end{figure}
}

\definecolor{green}{rgb}{0.2,0.8,0.2}

\begin{document}
\begin{center}

	{\LARGE\centering Classifications de programmes malicieux et non-malicieux\\ à partir de propriétés binaires}\\[1cm]

	{ Matthias \bsc{Beaupère}, Pierre \bsc{Granger}}\\[0.5cm]
	{Rapport DA - CHPS - \today}
\end{center}

\tableofcontents

\section{Présentation du jeu de données}
	Nos données proviennent de la base de données UCI\cite{UCI}.
	Cette base de données a été obtenue à partir de l'étude de 373 programmes informatiques malicieux et non-malicieux selon le processus expliqué dans un article de recherche en 2007 \cite{article}. Cet article développe une méthode permettant d'extraire des caractéristiques à partir d'exécutables malins et bénins afin d'effectuer par la suite une classification de ces exécutables permettant de les distinguer. Trois types de caractéristiques sont extraites : des n-uplets binaires, des n-uplets assembleur et des appels à des fonctions appartenant à des librairies extérieures. Les caractéristiques binaires sont extraites des exécutables binaires tandis que les caractéristique assembleur sont obtenues après désassemblage de l'exécutable. Les caractéristiques liées aux appels de fonctions sont extraites depuis l'entête du programme.

\section{Objectifs}
	Nous nous proposons dans ce projet d'utiliser le jeu de données précédemment décrit afin d'obtenir la meilleure classification possible entre les virus informatiques et les programmes bénins. Pour un même score, on s'attachera à optimiser le nombre de faux-négatifs car c'est le cas le plus préoccupant dans le cadre de la détection de virus. Nous avons choisi d'utiliser le language Python et plus particulièrement son module Scikit-learn \cite{sklearn} durant ce projet.

\section{Pré-traitement des données}
	Nous avons commencé notre étude des données par quelques visualisations de notre jeu de données. Nous avons tout d'abord visualisé l'histogramme du nombre de caractéristiques possédé par les programmes du jeu de données représenté sur la figure \ref{hist_features}. On peut observer sur cet histogramme que la majorité des programmes possèdent une centaine de caractéristiques tandis qu'ils sont très peu à les posséder toutes ou bien à n'en avoir aucune. On peut en outre remarquer que la quasi totalité des virus possèdent un nombre de caractéristique situé entre 80 et 110 tandis qu'il existe des programmes bénins avec plus ou moins de caractéristiques. Cette observation pourra nous mener à tenter de restreindre certaines analyses futures aux programmes possédant entre 80 et 110 caractéristiques en supposant que les programmes bénins ne respectant pas ce critère peuvent être considérés comme des valeurs extrèmes.
	On peut en outre observer sur l'histogramme représenté en figure \ref{hist_individuals} que la majorité des caractéristiques ne sont possédées que par quelques dizaines de programmes. On observe néanmoins qu'il existe un nombre non négligeable de caractéristiques partagées par un grand nombre de programmes. On pourra se proposer par la suite de ne pas considérer les caractéristiques correspondantes car elles sont moins significatives.


	\begin{center}
		\begin{figure}
			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}] table[y index=0] {data/hist_features_ok.dat};
			\legend{Programmes bénins}
			\end{axis}
			\end{tikzpicture}
			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}, fill=red!50!white, draw=red] table[y index=0] {data/hist_features_virus.dat};
			\legend{Programmes malicieux}
			\end{axis}
			\end{tikzpicture}

			\begin{tikzpicture}
			\begin{axis}[
			width=\linewidth,
			height=4cm,
			xmin=50,xmax=250,
			ymin=0, ymax=300,
			ybar interval=1,
			ybar legend,
			xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
			x tick label style= {rotate=90,anchor=east},
			xlabel={Nombre de caractéristiques},
			ylabel={Nombre de programmes}
			],
			\addplot+[hist={bins=20, data max=250,data min=50}, fill=black!50!white, draw=black]
			table[y index=0] {data/hist_features.dat};
			\legend{Ensemble des programmes}
			\end{axis}
			\end{tikzpicture}

			\caption{Histogramme du nombre de caractéristiques possédé par chaque programme\label{hist_features}}
		\end{figure}
	\end{center}

	\begin{center}
	\begin{figure}
	\begin{tikzpicture}
	\begin{axis}[
	width=\linewidth,
	height=6cm,
	xmin=0,xmax=400,
	ymin=0, ymax=300,
	ybar interval,
	xticklabel={[\pgfmathprintnumber\tick;\pgfmathprintnumber\nexttick [},
	x tick label style= {rotate=90,anchor=east},
	ylabel={Nombre de caractéristiques},
	xlabel={Nombre de programmes}
	],
	\addplot+[hist={bins=20, data max=400,data min=0}]
	table[y index=0] {data/hist_individuals.dat};
	% \addplot[sharp plot,mark=square*,black]
	% coordinates
	% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
	\end{axis}
	\end{tikzpicture}
	\caption{Histogramme du nombre de programme possédant chaque caractéristique\label{hist_individuals}}
	\end{figure}
	\end{center}

\section{Techniques de validation}

	On présente ici les deux techniques utilisées pour valider les modèles de classification.

	\subsection{Data-splitting}		
		La première technique de validation utilisée est la technique de data-splitting. On divise aléatoirement le jeu de données en deux. La première partie sert à entrainer le modèle tandis que la seconde est utilisée pour valider le modèle en comparant les prédictions du modèle et les valeurs réelles.
		Cette technique produit des résultats très différents suivant la répartition des données dans les deux jeux. C'est pourquoi on rejouera souvent un grand nombre de fois le data-splitting et on observera la moyenne et l'écart-type pour connaitre la robustesse de la validation.

	\subsection{Cross-validation}

		La deuxième technique consiste à diviser le jeu de données en $n$ parties égales. On itère sur chaque partie de la façon suivante: les $n-1$ autres parties servent à entrainer le modèle et la partie courante est utilisée pour le valider. 

\section{Différents algo}
	\subsection{Régression logistique}
		La régression logistique permet facilement d'effectuer une régression binomiale sur des caractéristiques binaires afin d'obtenir une classification binaire d'où sa mise en oeuvre dans le problème qui nous occupe.

		La régression logistique permet d'effectuer une pénalisation de type L1 ou L2 afin de limiter le nombre de caractéristiques significatives dans le calcul de la régression. Cette pénalisation peut se parametrer avec Scikit-Learn au travers d'un paramètre $C$ qui est l'inverse de la constante de régularisation. Ainsi on augmente la pénalisation lorsque l'on diminue $C$.

		On commence par étudier quelle valeur de $C$ permet d'obtenir les meilleurs résultats. On peut voir représenté sur la figure \ref{fig:l1_C} l'impact de la valeur de $C$ sur le score obtenu dans le cas de la pénalisation L1. On peut observer que la valeur optimale se situe aux alentours de $C=0.4$. En effet, pour une valeur inférieure, la constante de régularisation devient trop importantes et trop de caractéristiques sont éliminées d'où une chute du score. Pour $C>0.4$, on observe une légère pente descendante car l'impact de la pénalisation devient alors très faible. Le taux de faux-positifs commence alors à très légèrement augmenter. Il semble qu'aucune valeur spécifique permette d'optimiser le nombre de faux-négatifs par rapport aux faux-positifs. Nous avons aussi testé la pénalisation L2 mais elle offrait des résultats légèrement inférieurs. On choisit donc pour la suite la pénalisation L1 et $C=0.4$.

		Dans un second temps, on peut tenter d'optimiser la proportion à utiliser entre les données d'entrainement de test afin d'obtenir les meilleurs résultats. On peut observer sur la figure \ref{logreg_meanstd} les tracés de la valeur moyenne et de l'écart-type du score obtenus après 500 répétitions aléatoires. Le score moyen augmente en suivant une loi de puissance de paramètre $0.09$ lorsque la quantité de données d'entrainement augmente. Néanmoins l'écart-type commence à exploser lorsque la proportion des données d'entrainement dépasse $0.8$ ce qui est attendu car alors la quantité d'exemples de test devient très faible. Le choix le plus judicieux du paramètre de proportion semble alors être $0.8$ ce qui permet d'atteindre une précision moyenne de $\SI{87}{\percent}$.

		\begin{figure}
			\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
					width=0.7\linewidth,
					height=6cm,
					ylabel={Moyenne du score},
					xlabel={$C$ (L1)},
					legend style={at={(0.95,0.7)}},
					],
					\addplot table [x=C, y=correct, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=false, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\addplot table [x=C, y=missed, only marks] {data/evaluation_dump_LogReg_T95_l1_N100.dat};
					\legend{Résultat correct, Faux positif, Faux négatif}
				\end{axis}
			\end{tikzpicture}
			\caption{\'Evolution du score en fonction de l'importance de la pénalisation\label{fig:l1_C}}
			\end{center}
		\end{figure}

		\begin{center}
			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Score moyen},
						xlabel={Proportion utilisée pour l'apprentissage},
						clip mode=individual,
						],
						\addplot table [x=train_size, y=mean, only marks] {data/logreg_l1_c05_trainsize.dat};
						\addplot[samples=100, no markers, domain=0.1:0.99, style=thick, color=red]{x^0.09162945*exp(-0.12192647)};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Ecart type du score},
						xlabel={Proportion utilisée pour l'apprentissage}
						],
						\addplot table [x=train_size, y=std, only marks] {data/logreg_l1_c05_trainsize.dat};
						% \addplot[sharp plot,mark=square*,black]
						% coordinates
						% {(-1.5,0) (1.5,3) (4.5,4) (7.5,2) (10.5,6) (13.5,0)};
					\end{axis}
				\end{tikzpicture}
				\caption{Evolutions de la valeur moyenne et de l'écart type du score en fonction de la proportion de données utilisées pour l'apprentissage dans le cas de la régression logistique. L'évaluation est effectuée sur la partie complémentaire.\label{logreg_meanstd}}
			\end{figure}
		\end{center}


	\subsection{SVM}

		% \begin{figure}[h]
		% 	\centering
		% 	\begin{tikzpicture}
		% 		\begin{axis}[
		% 			xlabel={$Q_{\beta\beta}$ (\si{MeV})},
		% 			ylabel style={align=center},
		% 			ylabel={Events not depositing energy \\ in the considered medium (\si{\percent})},
		% 			legend pos=north east,
		% 			legend entries={fibers, buffer}]
		% 			\addplot table [x=Qbb, y=percent, only marks] {increase.txt};
		% 			\addplot table [x=Qbb, y=percent2, only marks] {increase.txt};
		% 		\end{axis}
		% 	\end{tikzpicture}
		% 	\caption{Proportions of events not depositing energy in the fibers as a function of $Q_{\beta\beta}$ of the considered isotope. \label{figure:en_vs_qbb}}
		% \end{figure}

	\subsection{SVC}
	\subsection{Classification avec kmeans}

	\subsection{Arbre de décision}

		\subsubsection{Arbre simple}
			Comme premier classificateur on utilise un unique arbre de décision. On compare les deux méthodes de validation : tout d'abord le data-splitting et ensuite la validation croisée. Dans chaque cas on observe l'impact de la proportion des données d'entrainement sur la précision et la robustesse du modèle.

			La figure \ref{data-splitting-dt} nous donne l'évolution de la précision moyenne et de l'écart-type obtenu pour un mille rejeu du data-splitting. Chaque abscisse donne un proportion des données de test. On observe un minimum d'écart-type à l'abscisse $175$. Cela montre qu'on a un modèle robuste avec des données de test représentant environ 45\% de la population.

			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Taille de l'ensemble de test}
						],
						\addplot table [x index=0, y index=1, only marks] {data/decision_tree.txt};
					\end{axis}
				\end{tikzpicture}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Ecart-type en précision},
						xlabel={Taille de l'ensemble de test}
						],
						\addplot table [x index=0, y index=2, only marks] {data/decision_tree.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Moyenne et Ecart-type pour 1000 data-splitting}
				\label{data-splitting-dt}
			\end{figure}
			\begin{figure}
				\begin{tikzpicture}
					\begin{axis}[
						width=0.5\linewidth,
						height=6cm,
						ylabel={Moyenne de précision},
						xlabel={Nombre de parts},
						ymin=0
						],
						\addplot table [x index=0, y index=1, only marks] {data/decision_tree_cv.txt};
					\end{axis}
				\end{tikzpicture}
				\caption{Moyenne pour 1000 cross-validations}
			\end{figure}


		\subsubsection{Random forest}
			
			\begin{tikzpicture}
				\begin{axis}[
					width=0.5\linewidth,
					height=6cm,
					ylabel={Moyenne de précision},
					xlabel={Nombre de parts},
					ymin=0
					],
					\addplot table [x index=0, y index=1, only marks] {data/random_forest.txt};
				\end{axis}
			\end{tikzpicture}


\section{Analyse des résultats}

\section{Pour aller plus loin...}

\section{Conclusion}
	On mérite au moins 21/20.

\bibliographystyle{unsrt}
\bibliography{synopsis.bib}

%\input{appendix}

\end{document}
